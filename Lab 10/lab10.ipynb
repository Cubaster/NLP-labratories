{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcjJ-YZy5-Pl"
   },
   "source": [
    "# Wykrywanie encji nazwanych z Flair\n",
    "\n",
    "To już ostatnie laboratoria zadaniowe, w związku z tym, jeśli znajdziecie chwilę wolnego czasu, wypełnijcie proszę ankietę: https://docs.google.com/forms/d/1rHPjpL70XdXRD-ILl3AHophPNUk0AhsFus1-mtkUPsI\n",
    "\n",
    "Pozwoli to mi poprawić laboratoria w przyszłości, z góry dziękuję :)\n",
    "\n",
    "# Flair\n",
    "\n",
    "Biblioteka Flair to bardzo popularne narzędzie do tagowania sekwencji. Zaintstalujmy ją"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4inJhzI0wQmM"
   },
   "outputs": [],
   "source": [
    "#!pip install flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyApRy6G7YQk"
   },
   "source": [
    "# Ładowanie zbioru danych i słownika z etykietami.\n",
    "\n",
    "**Zadanie1: (1 punkt):** Stwórz słownik etykiet z wczytanego korpusu korzystając z funkcji `make_label_dictionary()`. W naszym zbiorze, etykiety do wykrycia występują w kolumnie `ner`, której identyfikator został zapisany w linijce 6. Tutorial: https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_6_CORPUS.md może okazać się pomocny.\n",
    "\n",
    "Efektem działania powinna być lista etykiet np: \n",
    "`Dictionary with 20 tags: <unk>, Variable, Class, Application, User_Interface_Element, Code_Block, Language, Function, Data_Structure, Library, Data_Type, File_Type, File_Name, Version, HTML_XML_Tag, Device, Operating_System, Website, User_Name, Algorithm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eK84adKF6GLr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:03:36,928 File train has 741 questions and 897 answers.\n",
      "2022-05-24 10:03:36,960 File test has 249 questions and 315 answers.\n",
      "2022-05-24 10:03:36,984 File dev has 247 questions and 289 answers.\n",
      "2022-05-24 10:03:36,984 Reading data from C:\\Users\\Acer\\.flair\\datasets\\ner_english_stackoverflow\n",
      "2022-05-24 10:03:36,984 Train: C:\\Users\\Acer\\.flair\\datasets\\ner_english_stackoverflow\\train.txt\n",
      "2022-05-24 10:03:36,984 Dev: C:\\Users\\Acer\\.flair\\datasets\\ner_english_stackoverflow\\dev.txt\n",
      "2022-05-24 10:03:36,984 Test: C:\\Users\\Acer\\.flair\\datasets\\ner_english_stackoverflow\\test.txt\n",
      "2022-05-24 10:03:43,597 Filtering empty sentences\n",
      "2022-05-24 10:03:43,629 Corpus: 926 train + 294 dev + 311 test sentences\n",
      "2022-05-24 10:03:43,629 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "926it [00:00, 38561.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:03:43,661 Dictionary created for label 'ner' with 21 values: Application (seen 127 times), Class (seen 124 times), Variable (seen 122 times), User_Interface_Element (seen 99 times), Code_Block (seen 81 times), Function (seen 75 times), Data_Structure (seen 69 times), Language (seen 62 times), Library (seen 60 times), Data_Type (seen 40 times), File_Name (seen 34 times), File_Type (seen 33 times), Device (seen 26 times), Version (seen 25 times), HTML_XML_Tag (seen 23 times), Website (seen 17 times), Operating_System (seen 12 times), Algorithm (seen 9 times), User_Name (seen 8 times), Licence (seen 1 times)\n",
      "\n",
      "\n",
      "Etykiety do wykrycia\n",
      "Dictionary with 21 tags: <unk>, Application, Class, Variable, User_Interface_Element, Code_Block, Function, Data_Structure, Language, Library, Data_Type, File_Name, File_Type, Device, Version, HTML_XML_Tag, Website, Operating_System, Algorithm, User_Name, Licence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from flair.datasets import NER_ENGLISH_STACKOVERFLOW    # zbiór otagowanych postów na Stacku\n",
    "\n",
    "corpus = NER_ENGLISH_STACKOVERFLOW().downsample(0.1)   # pobieramy korpus i zmniejszamy jego wielkość\n",
    "corpus.filter_empty_sentences()                         # usuwamy puste zdania\n",
    "\n",
    "label_type = 'ner'   # identyfikator pod którym możemy dostać typy etykiet\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
    "print('\\n\\nEtykiety do wykrycia')\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlz60uuR83oR"
   },
   "source": [
    "# Embeddingi\n",
    "\n",
    "W narzędziu Flair możemy bardzo prosto składać ze sobą różne embeddingi. \n",
    "\n",
    "**Zad2 (2 punkty):** Zapoznaj się z działaniem `StackedEmbeddings` opisanego w https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md i zbuduj embeddingi zawierające reprezentacje pochodzące zarówno z Glove jak i Flairowe, oparte na `news-forward`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yzCwq37iwFo4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:09:06,471 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to C:\\Users\\Acer\\AppData\\Local\\Temp\\tmpd5olx8n3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 160000128/160000128 [02:08<00:00, 1249034.86B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:11:14,769 copying C:\\Users\\Acer\\AppData\\Local\\Temp\\tmpd5olx8n3 to cache at C:\\Users\\Acer\\.flair\\embeddings\\glove.gensim.vectors.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:11:15,001 removing temp file C:\\Users\\Acer\\AppData\\Local\\Temp\\tmpd5olx8n3\n",
      "2022-05-24 10:11:15,177 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to C:\\Users\\Acer\\AppData\\Local\\Temp\\tmps7naxwcl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 21494764/21494764 [00:14<00:00, 1489193.40B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:11:29,771 copying C:\\Users\\Acer\\AppData\\Local\\Temp\\tmps7naxwcl to cache at C:\\Users\\Acer\\.flair\\embeddings\\glove.gensim\n",
      "2022-05-24 10:11:29,803 removing temp file C:\\Users\\Acer\\AppData\\Local\\Temp\\tmps7naxwcl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:11:34,452 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-forward-0.4.1.pt not found in cache, downloading to C:\\Users\\Acer\\AppData\\Local\\Temp\\tmp37wahrub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 73034624/73034624 [00:47<00:00, 1541813.47B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:12:21,957 copying C:\\Users\\Acer\\AppData\\Local\\Temp\\tmp37wahrub to cache at C:\\Users\\Acer\\.flair\\embeddings\\news-forward-0.4.1.pt\n",
      "2022-05-24 10:12:22,069 removing temp file C:\\Users\\Acer\\AppData\\Local\\Temp\\tmp37wahrub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token[0]: \"The\"\n",
      "tensor([-3.8194e-02, -2.4487e-01,  7.2812e-01,  ..., -4.4014e-04,\n",
      "        -3.9301e-02,  1.0601e-02])\n",
      "Token[1]: \"grass\"\n",
      "tensor([-8.1353e-01,  9.4042e-01, -2.4048e-01,  ..., -3.7749e-04,\n",
      "        -2.3563e-02,  1.1700e-02])\n",
      "Token[2]: \"is\"\n",
      "tensor([-0.5426,  0.4148,  1.0322,  ..., -0.0061,  0.0112,  0.0100])\n",
      "Token[3]: \"green\"\n",
      "tensor([-0.6791,  0.3491, -0.2398,  ..., -0.0026, -0.0118,  0.0455])\n",
      "Token[4]: \".\"\n",
      "tensor([-3.3979e-01,  2.0941e-01,  4.6348e-01,  ..., -2.3405e-04,\n",
      "         3.8688e-03,  5.7725e-03])\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
    "\n",
    "embeddings = StackedEmbeddings([glove_embedding,\n",
    "                               flair_embedding_forward])\n",
    "\n",
    "\n",
    "embeddings.embed(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Wxgw7Uc91e3"
   },
   "source": [
    "# Tagger i trainer\n",
    "\n",
    "**Zadanie 3 (2 punkty)** Bazując na treściach opisanych w https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md przygotuj obiekt `SequenceTagger`, którego rozmiar wartswy ukrytej wyniesie 256. Do obiektu tego przekażemy stworzone wcześniej embeddingi, słownik `label_dict` i nazwę kolumny z etykietą ze zmiennej `label_type`. Ustawmy `use_crf` na True.\n",
    "\n",
    "Przygotuj obiekt `ModelTrainer`, który przyjmie zarówno nasz korpus jak i stworzony przed chwilą `SequenceTagger`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZqglzMPP92Fq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:20:39,392 SequenceTagger predicts: Dictionary with 81 tags: O, S-Application, B-Application, E-Application, I-Application, S-Class, B-Class, E-Class, I-Class, S-Variable, B-Variable, E-Variable, I-Variable, S-User_Interface_Element, B-User_Interface_Element, E-User_Interface_Element, I-User_Interface_Element, S-Code_Block, B-Code_Block, E-Code_Block, I-Code_Block, S-Function, B-Function, E-Function, I-Function, S-Data_Structure, B-Data_Structure, E-Data_Structure, I-Data_Structure, S-Language, B-Language, E-Language, I-Language, S-Library, B-Library, E-Library, I-Library, S-Data_Type, B-Data_Type, E-Data_Type, I-Data_Type, S-File_Name, B-File_Name, E-File_Name, I-File_Name, S-File_Type, B-File_Type, E-File_Type, I-File_Type, S-Device\n",
      "2022-05-24 10:20:39,504 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 10:20:39,512 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=2148, out_features=2148, bias=True)\n",
      "  (rnn): LSTM(2148, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=83, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-05-24 10:20:39,520 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 10:20:39,520 Corpus: \"Corpus: 926 train + 294 dev + 311 test sentences\"\n",
      "2022-05-24 10:20:39,520 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 10:20:39,520 Parameters:\n",
      "2022-05-24 10:20:39,520  - learning_rate: \"0.100000\"\n",
      "2022-05-24 10:20:39,520  - mini_batch_size: \"32\"\n",
      "2022-05-24 10:20:39,528  - patience: \"3\"\n",
      "2022-05-24 10:20:39,528  - anneal_factor: \"0.5\"\n",
      "2022-05-24 10:20:39,528  - max_epochs: \"5\"\n",
      "2022-05-24 10:20:39,528  - shuffle: \"True\"\n",
      "2022-05-24 10:20:39,528  - train_with_dev: \"False\"\n",
      "2022-05-24 10:20:39,528  - batch_growth_annealing: \"False\"\n",
      "2022-05-24 10:20:39,528 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 10:20:39,536 Model training base path: \"resources\\taggers\\example-upos\"\n",
      "2022-05-24 10:20:39,536 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 10:20:39,536 Device: cpu\n",
      "2022-05-24 10:20:39,536 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 10:20:39,536 Embeddings storage mode: cpu\n",
      "2022-05-24 10:20:39,536 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 10:20:49,284 epoch 1 - iter 2/29 - loss 3.50518780 - samples/sec: 6.57 - lr: 0.100000\n",
      "2022-05-24 10:20:59,830 epoch 1 - iter 4/29 - loss 2.40221937 - samples/sec: 6.07 - lr: 0.100000\n",
      "2022-05-24 10:21:09,953 epoch 1 - iter 6/29 - loss 1.95272943 - samples/sec: 6.32 - lr: 0.100000\n",
      "2022-05-24 10:21:17,669 epoch 1 - iter 8/29 - loss 1.64374097 - samples/sec: 8.30 - lr: 0.100000\n",
      "2022-05-24 10:21:28,935 epoch 1 - iter 10/29 - loss 1.50539309 - samples/sec: 5.68 - lr: 0.100000\n",
      "2022-05-24 10:21:41,521 epoch 1 - iter 12/29 - loss 1.34347310 - samples/sec: 5.09 - lr: 0.100000\n",
      "2022-05-24 10:21:51,117 epoch 1 - iter 14/29 - loss 1.26639831 - samples/sec: 6.67 - lr: 0.100000\n",
      "2022-05-24 10:22:00,624 epoch 1 - iter 16/29 - loss 1.16876008 - samples/sec: 6.74 - lr: 0.100000\n",
      "2022-05-24 10:22:09,564 epoch 1 - iter 18/29 - loss 1.12261237 - samples/sec: 7.16 - lr: 0.100000\n",
      "2022-05-24 10:22:23,158 epoch 1 - iter 20/29 - loss 1.07964407 - samples/sec: 4.71 - lr: 0.100000\n",
      "2022-05-24 10:22:32,913 epoch 1 - iter 22/29 - loss 1.04610619 - samples/sec: 6.56 - lr: 0.100000\n",
      "2022-05-24 10:22:42,277 epoch 1 - iter 24/29 - loss 1.00331999 - samples/sec: 6.84 - lr: 0.100000\n",
      "2022-05-24 10:22:51,281 epoch 1 - iter 26/29 - loss 0.97846792 - samples/sec: 7.11 - lr: 0.100000\n",
      "2022-05-24 10:23:07,961 epoch 1 - iter 28/29 - loss 0.95593109 - samples/sec: 3.84 - lr: 0.100000\n",
      "2022-05-24 10:23:13,358 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 10:23:13,358 EPOCH 1 done: loss 0.9416 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:33<00:00,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:23:46,646 Evaluating as a multi-label problem: False\n",
      "2022-05-24 10:23:46,662 DEV : loss 0.6106255650520325 - f1-score (micro avg)  0.0\n",
      "2022-05-24 10:23:46,686 BAD EPOCHS (no improvement): 0\n",
      "2022-05-24 10:23:46,686 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:23:51,907 epoch 2 - iter 2/29 - loss 0.64727534 - samples/sec: 12.26 - lr: 0.100000\n",
      "2022-05-24 10:23:55,081 epoch 2 - iter 4/29 - loss 0.65656022 - samples/sec: 20.16 - lr: 0.100000\n",
      "2022-05-24 10:23:57,487 epoch 2 - iter 6/29 - loss 0.69529290 - samples/sec: 26.60 - lr: 0.100000\n",
      "2022-05-24 10:24:01,006 epoch 2 - iter 8/29 - loss 0.67702470 - samples/sec: 18.19 - lr: 0.100000\n",
      "2022-05-24 10:24:04,268 epoch 2 - iter 10/29 - loss 0.65006792 - samples/sec: 19.62 - lr: 0.100000\n",
      "2022-05-24 10:24:06,514 epoch 2 - iter 12/29 - loss 0.62850015 - samples/sec: 28.49 - lr: 0.100000\n",
      "2022-05-24 10:24:10,064 epoch 2 - iter 14/29 - loss 0.61884006 - samples/sec: 18.03 - lr: 0.100000\n",
      "2022-05-24 10:24:13,638 epoch 2 - iter 16/29 - loss 0.61629270 - samples/sec: 17.91 - lr: 0.100000\n",
      "2022-05-24 10:24:16,140 epoch 2 - iter 18/29 - loss 0.61707122 - samples/sec: 25.58 - lr: 0.100000\n",
      "2022-05-24 10:24:19,610 epoch 2 - iter 20/29 - loss 0.60258833 - samples/sec: 18.49 - lr: 0.100000\n",
      "2022-05-24 10:24:25,279 epoch 2 - iter 22/29 - loss 0.59748703 - samples/sec: 11.29 - lr: 0.100000\n",
      "2022-05-24 10:24:29,101 epoch 2 - iter 24/29 - loss 0.59553586 - samples/sec: 16.75 - lr: 0.100000\n",
      "2022-05-24 10:24:31,716 epoch 2 - iter 26/29 - loss 0.58978325 - samples/sec: 24.55 - lr: 0.100000\n",
      "2022-05-24 10:24:35,722 epoch 2 - iter 28/29 - loss 0.59657725 - samples/sec: 15.98 - lr: 0.100000\n",
      "2022-05-24 10:24:36,577 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 10:24:36,577 EPOCH 2 done: loss 0.5964 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:24:38,608 Evaluating as a multi-label problem: False\n",
      "2022-05-24 10:24:38,624 DEV : loss 0.5657783150672913 - f1-score (micro avg)  0.0\n",
      "2022-05-24 10:24:38,648 BAD EPOCHS (no improvement): 0\n",
      "2022-05-24 10:24:38,648 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:24:42,198 epoch 3 - iter 2/29 - loss 0.71945618 - samples/sec: 18.03 - lr: 0.100000\n",
      "2022-05-24 10:24:45,948 epoch 3 - iter 4/29 - loss 0.64045540 - samples/sec: 17.07 - lr: 0.100000\n",
      "2022-05-24 10:24:48,627 epoch 3 - iter 6/29 - loss 0.60483913 - samples/sec: 23.89 - lr: 0.100000\n",
      "2022-05-24 10:24:53,464 epoch 3 - iter 8/29 - loss 0.56656777 - samples/sec: 13.23 - lr: 0.100000\n",
      "2022-05-24 10:24:56,286 epoch 3 - iter 10/29 - loss 0.57467295 - samples/sec: 22.68 - lr: 0.100000\n",
      "2022-05-24 10:24:59,348 epoch 3 - iter 12/29 - loss 0.56245224 - samples/sec: 20.90 - lr: 0.100000\n",
      "2022-05-24 10:25:02,642 epoch 3 - iter 14/29 - loss 0.55212823 - samples/sec: 19.47 - lr: 0.100000\n",
      "2022-05-24 10:25:05,904 epoch 3 - iter 16/29 - loss 0.56187348 - samples/sec: 19.62 - lr: 0.100000\n",
      "2022-05-24 10:25:11,022 epoch 3 - iter 18/29 - loss 0.55541006 - samples/sec: 12.53 - lr: 0.100000\n",
      "2022-05-24 10:25:13,932 epoch 3 - iter 20/29 - loss 0.54880414 - samples/sec: 22.05 - lr: 0.100000\n",
      "2022-05-24 10:25:17,986 epoch 3 - iter 22/29 - loss 0.55679791 - samples/sec: 15.79 - lr: 0.100000\n",
      "2022-05-24 10:25:20,536 epoch 3 - iter 24/29 - loss 0.56338382 - samples/sec: 25.09 - lr: 0.100000\n",
      "2022-05-24 10:25:24,694 epoch 3 - iter 26/29 - loss 0.55773201 - samples/sec: 15.42 - lr: 0.100000\n",
      "2022-05-24 10:25:28,580 epoch 3 - iter 28/29 - loss 0.55252693 - samples/sec: 16.50 - lr: 0.100000\n",
      "2022-05-24 10:25:29,923 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 10:25:29,923 EPOCH 3 done: loss 0.5525 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:25:32,065 Evaluating as a multi-label problem: False\n",
      "2022-05-24 10:25:32,073 DEV : loss 0.5394335985183716 - f1-score (micro avg)  0.0\n",
      "2022-05-24 10:25:32,097 BAD EPOCHS (no improvement): 0\n",
      "2022-05-24 10:25:32,105 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:25:36,007 epoch 4 - iter 2/29 - loss 0.47061525 - samples/sec: 16.40 - lr: 0.100000\n",
      "2022-05-24 10:25:40,005 epoch 4 - iter 4/29 - loss 0.50461264 - samples/sec: 16.01 - lr: 0.100000\n",
      "2022-05-24 10:25:42,772 epoch 4 - iter 6/29 - loss 0.43892016 - samples/sec: 23.14 - lr: 0.100000\n",
      "2022-05-24 10:25:49,256 epoch 4 - iter 8/29 - loss 0.44176066 - samples/sec: 9.87 - lr: 0.100000\n",
      "2022-05-24 10:25:52,390 epoch 4 - iter 10/29 - loss 0.45269606 - samples/sec: 20.42 - lr: 0.100000\n",
      "2022-05-24 10:25:55,468 epoch 4 - iter 12/29 - loss 0.45674425 - samples/sec: 20.85 - lr: 0.100000\n",
      "2022-05-24 10:25:59,106 epoch 4 - iter 14/29 - loss 0.45512965 - samples/sec: 17.59 - lr: 0.100000\n",
      "2022-05-24 10:26:01,665 epoch 4 - iter 16/29 - loss 0.47003571 - samples/sec: 25.02 - lr: 0.100000\n",
      "2022-05-24 10:26:06,623 epoch 4 - iter 18/29 - loss 0.48864170 - samples/sec: 12.91 - lr: 0.100000\n",
      "2022-05-24 10:26:09,861 epoch 4 - iter 20/29 - loss 0.49409356 - samples/sec: 19.77 - lr: 0.100000\n",
      "2022-05-24 10:26:12,787 epoch 4 - iter 22/29 - loss 0.50628822 - samples/sec: 21.93 - lr: 0.100000\n",
      "2022-05-24 10:26:14,929 epoch 4 - iter 24/29 - loss 0.50031999 - samples/sec: 29.98 - lr: 0.100000\n",
      "2022-05-24 10:26:18,343 epoch 4 - iter 26/29 - loss 0.49835121 - samples/sec: 18.75 - lr: 0.100000\n",
      "2022-05-24 10:26:21,781 epoch 4 - iter 28/29 - loss 0.50903287 - samples/sec: 18.62 - lr: 0.100000\n",
      "2022-05-24 10:26:23,069 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 10:26:23,069 EPOCH 4 done: loss 0.5059 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:26:25,155 Evaluating as a multi-label problem: False\n",
      "2022-05-24 10:26:25,163 DEV : loss 0.4891427755355835 - f1-score (micro avg)  0.0962\n",
      "2022-05-24 10:26:25,187 BAD EPOCHS (no improvement): 0\n",
      "2022-05-24 10:26:25,187 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:26:26,554 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 10:26:29,785 epoch 5 - iter 2/29 - loss 0.51810907 - samples/sec: 19.81 - lr: 0.100000\n",
      "2022-05-24 10:26:34,750 epoch 5 - iter 4/29 - loss 0.49324945 - samples/sec: 12.89 - lr: 0.100000\n",
      "2022-05-24 10:26:37,932 epoch 5 - iter 6/29 - loss 0.48192638 - samples/sec: 20.11 - lr: 0.100000\n",
      "2022-05-24 10:26:40,866 epoch 5 - iter 8/29 - loss 0.45414575 - samples/sec: 21.81 - lr: 0.100000\n",
      "2022-05-24 10:26:45,895 epoch 5 - iter 10/29 - loss 0.48830619 - samples/sec: 12.73 - lr: 0.100000\n",
      "2022-05-24 10:26:49,197 epoch 5 - iter 12/29 - loss 0.46514169 - samples/sec: 19.38 - lr: 0.100000\n",
      "2022-05-24 10:26:53,131 epoch 5 - iter 14/29 - loss 0.49760000 - samples/sec: 16.30 - lr: 0.100000\n",
      "2022-05-24 10:26:56,185 epoch 5 - iter 16/29 - loss 0.49744483 - samples/sec: 20.96 - lr: 0.100000\n",
      "2022-05-24 10:26:59,463 epoch 5 - iter 18/29 - loss 0.49298045 - samples/sec: 19.52 - lr: 0.100000\n",
      "2022-05-24 10:27:02,589 epoch 5 - iter 20/29 - loss 0.48542078 - samples/sec: 20.53 - lr: 0.100000\n",
      "2022-05-24 10:27:05,763 epoch 5 - iter 22/29 - loss 0.48290232 - samples/sec: 20.21 - lr: 0.100000\n",
      "2022-05-24 10:27:09,233 epoch 5 - iter 24/29 - loss 0.48563497 - samples/sec: 18.44 - lr: 0.100000\n",
      "2022-05-24 10:27:11,864 epoch 5 - iter 26/29 - loss 0.48210332 - samples/sec: 24.33 - lr: 0.100000\n",
      "2022-05-24 10:27:16,469 epoch 5 - iter 28/29 - loss 0.48698542 - samples/sec: 13.90 - lr: 0.100000\n",
      "2022-05-24 10:27:19,235 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 10:27:19,235 EPOCH 5 done: loss 0.4820 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:27:21,282 Evaluating as a multi-label problem: False\n",
      "2022-05-24 10:27:21,298 DEV : loss 0.4612547755241394 - f1-score (micro avg)  0.1276\n",
      "2022-05-24 10:27:21,314 BAD EPOCHS (no improvement): 0\n",
      "2022-05-24 10:27:21,322 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:27:24,208 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 10:27:24,208 loading file resources\\taggers\\example-upos\\best-model.pt\n",
      "2022-05-24 10:27:24,928 SequenceTagger predicts: Dictionary with 83 tags: O, S-Application, B-Application, E-Application, I-Application, S-Class, B-Class, E-Class, I-Class, S-Variable, B-Variable, E-Variable, I-Variable, S-User_Interface_Element, B-User_Interface_Element, E-User_Interface_Element, I-User_Interface_Element, S-Code_Block, B-Code_Block, E-Code_Block, I-Code_Block, S-Function, B-Function, E-Function, I-Function, S-Data_Structure, B-Data_Structure, E-Data_Structure, I-Data_Structure, S-Language, B-Language, E-Language, I-Language, S-Library, B-Library, E-Library, I-Library, S-Data_Type, B-Data_Type, E-Data_Type, I-Data_Type, S-File_Name, B-File_Name, E-File_Name, I-File_Name, S-File_Type, B-File_Type, E-File_Type, I-File_Type, S-Device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:40<00:00,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:28:05,211 Evaluating as a multi-label problem: False\n",
      "2022-05-24 10:28:05,227 0.2667\t0.08\t0.1231\t0.0739\n",
      "2022-05-24 10:28:05,227 \n",
      "Results:\n",
      "- F-score (micro) 0.1231\n",
      "- F-score (macro) 0.0487\n",
      "- Accuracy 0.0739\n",
      "\n",
      "By class:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                 Class     0.3226    0.3774    0.3478        53\n",
      "              Variable     0.0769    0.0250    0.0377        40\n",
      "           Application     0.3333    0.1389    0.1961        36\n",
      "User_Interface_Element     0.0000    0.0000    0.0000        44\n",
      "              Function     0.0000    0.0000    0.0000        35\n",
      "            Code_Block     0.0000    0.0000    0.0000        25\n",
      "        Data_Structure     0.0000    0.0000    0.0000        24\n",
      "             Data_Type     0.0000    0.0000    0.0000        17\n",
      "               Library     0.0000    0.0000    0.0000        15\n",
      "             File_Name     0.0000    0.0000    0.0000        15\n",
      "              Language     0.5000    0.0833    0.1429        12\n",
      "             File_Type     1.0000    0.1111    0.2000         9\n",
      "               Website     0.0000    0.0000    0.0000         6\n",
      "               Version     0.0000    0.0000    0.0000         5\n",
      "      Operating_System     0.0000    0.0000    0.0000         4\n",
      "          HTML_XML_Tag     0.0000    0.0000    0.0000         4\n",
      "                Device     0.0000    0.0000    0.0000         3\n",
      "             Algorithm     0.0000    0.0000    0.0000         2\n",
      "             User_Name     0.0000    0.0000    0.0000         1\n",
      "\n",
      "             micro avg     0.2667    0.0800    0.1231       350\n",
      "             macro avg     0.1175    0.0387    0.0487       350\n",
      "          weighted avg     0.1348    0.0800    0.0872       350\n",
      "\n",
      "2022-05-24 10:28:05,227 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 10:28:05,235 loading file resources/taggers/example-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 10:28:05,882 SequenceTagger predicts: Dictionary with 83 tags: O, S-Application, B-Application, E-Application, I-Application, S-Class, B-Class, E-Class, I-Class, S-Variable, B-Variable, E-Variable, I-Variable, S-User_Interface_Element, B-User_Interface_Element, E-User_Interface_Element, I-User_Interface_Element, S-Code_Block, B-Code_Block, E-Code_Block, I-Code_Block, S-Function, B-Function, E-Function, I-Function, S-Data_Structure, B-Data_Structure, E-Data_Structure, I-Data_Structure, S-Language, B-Language, E-Language, I-Language, S-Library, B-Library, E-Library, I-Library, S-Data_Type, B-Data_Type, E-Data_Type, I-Data_Type, S-File_Name, B-File_Name, E-File_Name, I-File_Name, S-File_Type, B-File_Type, E-File_Type, I-File_Type, S-Device\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "\n",
    "tagger = SequenceTagger(hidden_size=256,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=label_dict,\n",
    "                        tag_type = label_type,\n",
    "                        use_crf = True)    # TODO\n",
    "trainer = ModelTrainer(tagger, corpus)   # TODO\n",
    "\n",
    "\n",
    "#stworzony trainer możemy zacząć trenować!\n",
    "trainer.train('resources/taggers/example-upos',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=5)\n",
    "\n",
    "# a kiedy wytrenujemy, wczytujemy najlepszy model.\n",
    "model = SequenceTagger.load('resources/taggers/example-upos/final-model.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxrd6m0H_-SJ"
   },
   "source": [
    "# Predykcja z udziałem modelu\n",
    "\n",
    "Jeśli model został wytrenowany, poniżej znajdziemy fragment kodu, który może wykryć encje w zdaniach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Koq76zqawM3P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"huge files can be opened from Python 3 .\" → [\"Python\"/Application]\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "# Jeśli nasz model się wyuczył, powinien wykryć Python jako język.\n",
    "# Uwaga, ponieważ pracujemy na niewielkim podzbiorze zbioru danych (downsample(0.1) próbkuje 10%), \n",
    "# otrzymywane wyniki mogą być kiepskiej jakości, najlepiej zwiększyść ilość danych \n",
    "# jeśli pracujemy w domu.\n",
    "sentence = Sentence('huge files can be opened from Python 3.')   # stwórz obiekt zdania\n",
    "model.predict(sentence)                                         # wykryj encje nazwane\n",
    "print(sentence.to_tagged_string())                              # wyświetl zdanie i wykryte w nim encje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOgY6c2y2eWb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "lab10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
